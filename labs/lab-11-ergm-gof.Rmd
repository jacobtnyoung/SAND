---
title: "Lab 11 - Simulation and Goodness of Fit with Exponential Random Graph Models (ERGMs) in R"
date: "CRJ 605 Statistical Analysis of Networks"
output: 
  html_document:
    df_print: paged
    theme: lumen
    highlight: haddock
    toc: yes
    toc_float: yes
    code_fold: show
    self_contained: true
---
<style>
body {
text-align: left}
</style>

```{r, echo=FALSE}

# set the defaults for the codechunks
knitr::opts_chunk$set( eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE )

```

```{r,echo=FALSE}

# libraries needed

library( sna )     # for sna functions
library( network ) # for working with network objects
library( ergm )    # for working with ergms

```

----

<br>

In the [Introduction to Exponential Random Graph Models (ERGMs) lecture](../lectures/lecture-08-ergm.pdf) you were introduced to several examples of models from the exponential family of random graphs and we worked through those models in the [Introduction to Exponential Random Graph Models (ERGMs) in R](../labs/lab-10-ergm-intro.html) lab. 

This lab continues working with ERGMs in R using the `ergm` package. Specifically, we ask the question: *how do we evaluate whether our model is a good fit to the data?* This is the notion of "goodness of fit" and we can assess how well our model fits the data using the `gof()` function in the `ergm` package.

# **Evaluation Model Fit for the PINS *Get Along With* Network**  

Recall that in the [Introduction to Exponential Random Graph Models (ERGMs) in R](../labs/lab-10-ergm-intro.html) lab we estimated a series of ERGMs using the *get along with* network from PINS. Here, we want to re-estimate the models and examine goodness of fit.

## Setting Up

First, let's bring in the data, create the network object, and assign attributes.

```{r}

# load the libraries we need
library( sna )
library( network )
library( ergm )

# set the location for the file
loc <- "https://github.com/jacobtnyoung/sna-textbook/raw/main/data/data-PINS-getalong-w1-adj.csv"

# read in the .csv file
gaMat <- as.matrix(
  read.csv( 
    loc,
    as.is = TRUE,
    header = TRUE,
    row.names = 1 
    )
  )

# use the symmetrize() function to create an undirected matrix
gaMatU <- symmetrize( gaMat, rule = "strong" )

# create the network object
gaNetU <- as.network( gaMatU, directed = FALSE )


# define the attributes object
attrs <- read.csv( 
    "https://raw.githubusercontent.com/jacobtnyoung/sna-textbook/main/data/data-PINS-w1-age-race-attributes.csv",
    as.is = TRUE,
    header = TRUE 
    )

# let's recode the single 4 to a 1
race.recoded <- attrs[,2]
race.recoded[ race.recoded == 4 ] <- 1

# now assign the recoded value
gaNetU %v% "Age" <- attrs[,1]
gaNetU %v% "Race" <- race.recoded

```

<br>

Now, let's estimate a few models. We will estimate several (each subsequent model will include the prior terms):  

  + An edge independence model  
  + A model where we add a term where `Race` influences degree  
  + A model where we add a term where there is homophily based on `Race`  
  + A model where we take into account transitivity
  
<br>

Ok, let's run the models. (remember that we can use the `summary()` function on the model object to summarize the results).

```{r, message=FALSE, warning=FALSE}

# edge independence model
m1.gaNetU <- ergm( gaNetU ~ edges ) 

# add the effect of Race on degree
m2.gaNetU <- ergm( gaNetU ~ edges  + nodefactor( "Race" ) ) 
  
# add the homophily effect for Race  
m3.gaNetU <- ergm( gaNetU ~ edges + nodematch( "Race" ) )

# add the effect for transitivity  
m4.gaNetU <- ergm( gaNetU ~ edges + nodematch( "Race", diff=TRUE ) + gwesp( decay = 0.25, fixed = TRUE ),
  control = control.ergm( seed = 605 ) ) 

```

## **The `simulate.ergm()` or `simulate()` and `control.ergm()` Functions**  

How can we go about assessing model fit? What would a good fitting model do? Well, one way to think about this is whether the model we estimate reproduces structures in the data. In other words, if we estimate a model, then simulated some data from that model, we could say: "does the simulated network **look like** our observed network?" This is the logic of how we will approach goodness of fit with our models. 

First, we need to think about simulating a network (or networks) from our model. We can do this using the `simulate.ergm()` or `simulate()` function that is built into the `ergm` package. This function randomly samples networks from the specified model. We can examine the function using `?simulate.ergm`. Let's see how it works:

```{r, message=FALSE}

# simulate a network from the edge independence model
sim.m1.gaNetU <- simulate(
  m1.gaNetU,               # the model we want to simulate from
  nsim=1,                  # simulate 1 network
  seed = 605               # set the seed to reproduce results
)

```

Boom! You simulated a network. Now what? Take a look at what we did.

```{r}

# the function creates an object of class network
class( sim.m1.gaNetU )

# look at the simulated network
sim.m1.gaNetU

```

Awesome! We have an object of class `network` that has the attributes of our observed data. Now, we can compare our observed network to our simulated network.

```{r}

# set the margins
par( mfrow=c( 1,2 ), 
     mar=c( 0.1, 0.5, 2, 0.5 ) )

# set the seed
set.seed( 605 )

# create the first plot
gplot( 
  gaNetU, 
  gmode = "graph",
  edge.col="grey40", 
  vertex.col="#f71505",
  main = "PINS Get\n Along With Network (Undirected)"
  )

# create the second plot for the simulated network
gplot( 
  sim.m1.gaNetU, 
  gmode = "graph",
  edge.col = "grey40", 
  vertex.col="#11adf5",
  main = "Network Simulated from\n Edge Independence Model"
  )

```

*How is the network different from the network generated from the edge independence model? What are the structural features that the model is not capturing?*  

<br>

## **Simulating more complex models and more graphs**  

Well, dang. It looks like our model is doing a great job reproducing the structure in our observed network.

Let's take a look at the additional models we created:

```{r}

# simulate a network from the degree effect for Race model
sim.m2.gaNetU <- simulate( m2.gaNetU, nsim=1, seed = 605 )

# simulate a network from the homophily model
sim.m3.gaNetU <- simulate( m3.gaNetU, nsim=1, seed = 605 )

# simulate a network from transitivity model
sim.m4.gaNetU <- simulate( m4.gaNetU, nsim=1, seed = 605 )

```

Now that we have our simulated networks, let's plot them.

```{r}

# set the margins
par( mfrow=c( 2,2 ), 
     mar=c( 0.1, 0.5, 2, 0.5 ) )

# set the seed
set.seed( 605 )

# create the first plot
gplot( 
  gaNetU, 
  gmode = "graph",
  edge.col="grey40", 
  vertex.col="#f71505",
  main = "PINS Get\n Along With Network (Undirected)"
  )

# create the second plot for the simulated network
gplot( 
  sim.m2.gaNetU, 
  gmode = "graph",
  edge.col = "grey40", 
  vertex.col="#11adf5",
  main = "Network Simulated from\n Degree Model"
  )

# create the third plot for the simulated network
gplot( 
  sim.m3.gaNetU, 
  gmode = "graph",
  edge.col = "grey40", 
  vertex.col="#e707f2",
  main = "Network Simulated from\n Homophily Model"
  )

# create the fourth plot for the simulated network
gplot( 
  sim.m4.gaNetU, 
  gmode = "graph",
  edge.col = "grey40", 
  vertex.col="#17f207",
  main = "Network Simulated from\n Transitivity Model"
  )


```

*What do think? As our models become more complex, are we doing better at reproducing the structures we observe?*

<br>

## **Goodness-of-fit (the basic logic)**  

Recall that we are fitting a model to observed data. That is, we are specifying the stochastic process that generated our observed data. We have specified local processes that generate our observed network. So, one way to determine how well the model fits the data is to see how well the model generates global network properties. That is, if the processes we have specified are operating, would we get the degree distribution (for example) we observe?

We can get a sense of how well the model is representing the observed network based on the visual comparison with the simulated networks (as we did above). In addition, we could look at whether our simulated networks are reproducing particular structures in our network.

We can use the `summary()` function and use the `ergm` terms to return descriptive stats on the networks (i.e. the observed network and the simulated networks). Let's take a look at the degree distribution as well as the number of triangles in our observed network and our simulated networks:  

```{r}

# let's see how this works for our observed network

summary( 
  gaNetU            # the network we want summary info on 
  ~ edges           # give the edges; note the ~
  + degree( 0:5 )   # count of degrees 0 through 5
  + triangle        # count of triangles
  )

```  

The output shows that the Bali network has:  

* `r summary( gaNetU ~ edges + degree( 0:5 ) + triangle )[1]` edges  

* `r summary( gaNetU ~ edges + degree( 0:5 ) + triangle )[2]` nodes with degree 0, `r summary( gaNetU ~ edges + degree( 0:5 ) + triangle )[3]` with degree 1, and so on to degree 5. 

* `r summary( gaNetU ~ edges + degree( 0:5 ) + triangle )[8]` triangles (i.e. *i*-*j*, *j*-*k*, & *i*-*k*)  

<br>

Now, let's take this info for our observed network and do the same for the simulated network from the fourth model. Then, we can look at whether the simulation is reproducing the structures we observe in the network.

```{r}

summary( 
  sim.m4.gaNetU   
  ~ edges         
  + degree( 0:5 ) 
  + triangle      
  )

```

Let's build a table to compare them:

```{r}

# put a table together for ease of comparing
obsSimTab <- cbind(
  summary( gaNetU  ~ edges + degree( 0:5 ) + triangle ),
  summary( sim.m4.gaNetU  ~ edges + degree( 0:5 ) + triangle )
)

# add some names and then examine the table
colnames( obsSimTab ) <- c( "Obs Net", "Sim Net" )
obsSimTab

```

*Looking through the table, how well is the model representing the structures we have decided to examine?*

<br>

### *Going Behind One Network*

So far, we have only looked at one simulation. Alternatively, we could run a lot of simulations and examine the distribution of a particular structural property (e.g. triangles). In the `simulate()` function, we can use several arguments to give us what we want:  

  * The `monitor=` argument to pass any specific terms we want to simulate. Since we are focusing just on the number of triangles, we would use `monitor=~triangle`. Note the incorporation of the `~` in the `monitor=` argument.  
  
  * We can also use the `output=` argument to just calculate stats rather than generating networks. Since we are only interested in the stats and don't want the networks, we use `output="stats"`.

<br>

Let's simulate 500 networks and take a look at the results:

```{r}

# run the simulation

gaNetU.large.sim <- simulate(
  m4.gaNetU,                # the model to simulate from
  nsim = 500,               # ask for 500 simulations
  monitor = ~ triangle,     # we want it to focus on the triangles
  output = "stats",           # just keep the stats, not the networks
  seed = 605                # set the seed to reproduce the results
)

```

Boom! We simulated 500 networks from our model. 

Let's see what it gave us.

```{r}

head( gaNetU.large.sim )

```

We can see that it reports the count of all the terms in the model in the columns and each row is the count for each simulated network.

Now, we can plot the summary stats for all the simulated networks to visualize the information.

```{r}

hist( 
  gaNetU.large.sim[,"triangle"],  # plot the triangle counts from each simulation
  main = "Simulations \n (X shows observed network)", # add a title
  xlim = c( 0,50 ), # set the x axis limits
  ylim = c( 0,200 ), # set the y axis limits
  xlab = "Number of triangles",  # label the x axis
  ylab = "Number of simulated networks" #label the y axes 
  )

# add a mark where the observed count is
points(
  summary( 
    gaNetU ~ triangle ),
  4, 
  pch="X", 
  cex=2, 
  col="red"
  )

```

*In looking at the simulation of the triangles, is our model generating as much transitivity as we observe in the network?*  

<br>

## **Goodness-of-fit with the `gof()` function**  

As we just saw, we can simulate lots of networks and then compare our observed network to the networks simulated from the model estimates. In `ergm`, there is a function that does this for us, `gof()`. The `gof()` function calculates *p*-values for geodesic distance, degree, and reachability summaries to diagnose the goodness-of-fit of exponential family random graph models. We can examine the help page for the `gof()` function using `?gof`.  

As shown in the help, the `gof()` function takes a fitted `ergm` object (i.e. an estimated model), and uses the `GOF=` argument to specify what summaries information we want to calculate for our **simulated** networks. Rather than simulating the networks, then calculating the stats, then creating a plot, the `gof()` function does all of this for us! (how nice).  

The `GOF=` argument takes a formula object, of the form `~ <model terms>` specifying the statistics to use to diagnosis the goodness-of-fit of the model. They do not need to be terms that are in the model, and typically are not. Currently supported terms are the degree distribution (`degree` for *undirected graphs*, or `idegree` and/or `odegree` for *directed graphs*), geodesic distances (`distance`), shared partner distributions (`espartners` [1 edge-wise shared partner is *i*-*j*, *j*-*k*, and *i*-*k*] and `dspartners` [1 dyad-wise shared partner is *j*-*k* and *i*-*k*]), the triad census (`triadcensus`), and the terms of the original model (`model`). The default formula for undirected networks is `~ degree + espartners + distance + model`, and the default formula for directed networks is `~ idegree + odegree + espartners + distance + model`. 

Let's go ahead and take a look at this with the `m4.gaNetU` model we estimated above where:  

  * `ergm( gaNetU ~ edges + nodematch( "Race", diff=TRUE ) + gwesp( decay = 0.25, fixed = TRUE )`
  
We want to calculate the degree distribution (`degree`), the edge-wise shared partner distribution (`espartners`), and the geodesic distances (`distance`). 


```{r}

m4.gaNetU.gof <- gof(
  m4.gaNetU,               # our estimated model
  GOF = ~degree            # the degree distribution 
    + espartners           # the edge-wise shared partners distribution
    + distance,            # the geodesic distance distribution
  verbose = TRUE,          # we want it to tell us what it is doing while it is doing it
  control = control.gof.ergm( seed = 605 ) # set the seed to reproduce results 
)

# print out the goodness of fit info
m4.gaNetU.gof

```

The object `m4.gaNetU.gof` shows the goodness-of-fit for the degree distribution, the edge-wise shared partner distribution, and the geodesic distances. Each table shows the value in the observed network (`obs`) as well as the minimum (`min`), mean (`mean`), and maximum (`max`) of that value in the **simulations**.  

The *p*-value column (`p-value`) is the proportion of the simulated values of the statistic that are at least as extreme as the observed value. *Large* values indicate that the simulated networks are similar to the observed network. Values less than 0.05 demonstrate a significant difference between the observed network and the simulated networks.  

<br>

We can reference each table using the `$pval` operator. Take a look at the names using: `names(m4.gaNetU.gof)`. Let's take a look at the degree distribution first:


```{r}

m4.gaNetU.gof$pval.deg

```

In looking through the *Goodness-of-fit for degree* table, what do the *p*-values tell us?

The degree distribution in the simulated data are matching well with the degree distribution for the observed data. In other words, our model (i.e. `ergm( gaNetU ~ edges + nodematch( "Race", diff=TRUE ) + gwesp( decay = 0.25, fixed = TRUE )`) is reproducing a degree distribution that is very similar to the degree distribution in our observed data.

Now let's look at the other distributions. Take a look at the *Goodness-of-fit for edge-wise shared partner* table:

```{r}

m4.gaNetU.gof$pval.espart

```

Recall that an edge-wise shared partner of 1 or `esp1` is *i*-*j*, *j*-*k*, and *i*-*k*. An edge-wise shared partner of 2 or `esp2` is *i*-*j*, *j*-*k* and *i*-*k*, as well as *i*-*l* and *l*-*l*. And so on... 

*What is the interpretation of this table?* 

***Conceptually, what does the difference (or lack thereof?) between the simulated networks and the observed networks, based on the edge-wise shared partner distribution tell us?***

<br>

Now, take a look at the *Goodness-of-fit for minimum geodesic distance* table:

```{r}

m4.gaNetU.gof$pval.dist

```

Recall that a geodesic is the shortest path between two nodes. The distribution shows the count of these (when it shows `Inf`, this indicates the number of dyads that are unreachable).

*What is the interpretation of this table?*

<br>

Finally, we can plot the `gof()` object and examine the simulated and observed data.

```{r}

# set the plot panes
par( mfrow = c( 2,2 ) )

plot( m4.gaNetU.gof )

```

Each plot shows boxplots for the values of the simulated networks. The **dark** line in each plot is the network statistic for the *observed network*. Situations where the dark line falls outside of the boxplots indicates that the simulation is not reproducing that particular structural aspect of the network.

*Overall, how well is our model at reproducing the observed distributions?*

<br>

As a contrast, let's look at the goodness of fit for the model where we exclude the term to account for transitivity in the network. Recall that the `m3.gaNetU` model was: `r m3.gaNetU$formula`.

```{r}

# run the gof function
m3.gaNetU.gof <- gof(
  m3.gaNetU,               # our estimated model
  GOF = ~degree            # the degree distribution 
    + espartners           # the edge-wise shared partners distribution
    + distance,            # the geodesic distance distribution
  verbose = TRUE,          # we want it to tell us what it is doing while it is doing it
  control = control.gof.ergm( seed = 605 ) # set the seed to reproduce results 
)

# plot the gof diagnostics
par( mfrow = c( 2,2 ) )
plot( m3.gaNetU.gof )

```

Now, let's ask a few questions:  

  * Which distributions is the model doing a good job reproducing?  
  * Where does it not do a good job? (Why is this the case?)

<br>

# **Evaluation Model Fit for the PINS *Power/Influence* Network**  

!!!HERE with going through 











!!!!HERE WITH WORKING this IN!


# **Simulating Alternative Models**  

Suppose we wanted to simulate a model where the effect of homophily is less strong. In other words, what would *this* network look like if there was not homophily? We can do this by plugging new values into the `simulate.ergm` function.  

Since a fitted `ergm` model is of class `ergm`, it has several parts that we can reference as objects:

```{r,echo=TRUE,eval=TRUE,message=FALSE,include=TRUE}
# check the class.
class(role.Bali)

# see the pieces of the ergm object.
names(role.Bali)

# the coefficients are an object that we can take, modify, and use with the simulation.
role.Bali$coef

# Let's create a new object that is just the model coefficients.
no.homophily.coef <- role.Bali$coef

# Now, let's change the effect of nodematch for "role" to be zero.
  # That is the sixth element in the vector, so we index accordingly.
no.homophily.coef[6] <- 0 

# Now, the effect is zero.
no.homophily.coef

# now, plug the edited coefficient into a simulation.
no.homophily.sim <- simulate(
  role.Bali, 
  coef = no.homophily.coef, # tell it to use the new coefficents.
  verbose = TRUE # tell it to show us what it is doing.
) 
# Now, plot the simulated network with no homophily.
gplot(no.homophily.sim, main="No Homophily Simluation",vertex.col=role.col, gmode="graph")
```

*How does the simulated network differ from the* `Bali` *network?*


!!!THIS ALL NEEDS TO BE UPDATED TO THE other lab setup for the bottom


***  

#### ***Questions?***


<br>

##### ***Please*** report any needed corrections to the [Issues](https://github.com/jacobtnyoung/SAND/issues/new) page. Thanks!

<br>
<br>


###### ***Last updated `r format(Sys.time(), '%d %B, %Y')`***