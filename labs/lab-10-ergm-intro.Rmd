---
title: "Lab 10 - Introduction to Exponential Random Graph Models (ERGMs) in R"
date: "CRJ 605 Statistical Analysis of Networks"
output: 
  html_document:
    df_print: paged
    theme: lumen
    highlight: haddock
    toc: yes
    toc_float: yes
    code_fold: show
    self_contained: true
---

```{r,echo=FALSE,eval=TRUE,message=FALSE,warning=FALSE}

library( network )
library( sna )
library( ergm )
```

<style>
body {
text-align: left}
</style>

```{r, echo=FALSE}

# set the defaults for the codechunks
knitr::opts_chunk$set( eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE )

```

```{r,echo=FALSE}

# libraries needed

library( sna )     # for sna functions
library( network ) # for working with network objects
library( ergm )    # for working with ergms

```

----

<br>

In the [Introduction to Exponential Random Graph Models (ERGMs) lecture](../lectures/lecture-08-ergm.pdf) you were introduced to several examples of models from the exponential family of random graphs. This lab provides an introduction to ERGMs in R using the `ergm` package. We will work through different dependence specifications of the model reviewed in the lecture (e.g. dyadic independence) and show how to incorporate node level attributes into the model.

<br>

# **Modeling Friendship in the PINS *Get Along With* Network**  

For the *get along with* network, individuals could have asymmetric nominations. That is, *i* could nominate *j* and *j* didn't necessarily nominate *i*. But, we are going to **symmetrize** the network by only taking ties for which ***both*** *i* and *j* indicated that the get along with the other person. This will give us an undirected network.
 
```{r}

# load the libraries we need
library( sna )
library( network )

# set the location for the file
loc <- "https://github.com/jacobtnyoung/sna-textbook/raw/main/data/data-PINS-getalong-w1-adj.csv"

# read in the .csv file
gaMat <- as.matrix(
  read.csv( 
    loc,
    as.is = TRUE,
    header = TRUE,
    row.names = 1 
    )
  )

# use the symmetrize() function to create an undirected matrix
gaMatU <- symmetrize( gaMat, rule = "strong" )

# create the network object
gaNetU <- as.network( gaMatU, directed = FALSE )

```

<br>


```{r, fig.show="hide"}

# Set the coordinates
set.seed( 605 )
coords <- gplot( gaNetU )

```


```{r, echo=TRUE, fig.align="center"}

gplot( 
  gaNetU, 
  gmode = "graph",
  edge.col="grey40", 
  vertex.col="#c78c71",
  coord = coords,
  main = "PINS Get\n Along With Network (Undirected)"  
  )

```

*Think about the structure here. What do you notice?*  

*How might we go about incorporating this information into a model of the network?*  

<br>

Before we get going, let's define some graphical objects we will use.

```{r}

# define the number of nodes
g <- dim( gaMatU )[1]

# define the number of edges
l <- sum( gaMatU )/2

# define the density
den <- l / ( g *( g - 1 ) / 2 ) 

den

```

*What is the interpretation of the density?*  

<br>

Recall that the exponential random graph model seeks to model the underlying processes that generated the observed network. Let's create a random graph with the same nodes, edges, and density as the `gaNetU` network and compare them by using the `rgraph()` function in the `sna` package:

```{r, message=FALSE}

?rgraph

# set the seed to reproduce these results
set.seed( 605 )

# generate the random graph
random.graph <- rgraph(
  g,                   # the number of nodes in the network
  1,                   # we want just 1 random graph 
  tprob = den,         # the density of the network 
  mode = "graph"       # it is undirected 
  )

# now coerce the random graph to a network object
random.net <- as.network( random.graph, directed = FALSE )

```

<br>

We can now compare our observed data with a graph that has the same density and the edges are randomly distributed over the nodes.

```{r}

# set the margins
par( mfrow=c( 1,2 ), 
     mar=c( 0.1, 0.5, 2, 0.5 ) )

# set the seed
set.seed( 605 )

# create the first plot
gplot( 
  gaNetU, 
  gmode = "graph",
  edge.col="grey40", 
  vertex.col="#c78c71",
  coord = coords,
  main = "PINS Get\n Along With Network (Undirected)"
  )

# create the second plot
gplot( 
  random.net, 
  gmode = "graph",
  edge.col = "grey40", 
  vertex.col="#069e6e",
  main = "Random network"
  )

```

*How is the Get Along With network different from the random network?*  

<br>

### **Adding Attributes (revisited)**

Recall that there is an attributes file that we can attach to these data. Let's load that and use these attributes in our plot.

```{r}

# define the attributes object
attrs <- read.csv( 
    "https://raw.githubusercontent.com/jacobtnyoung/sna-textbook/main/data/data-PINS-w1-age-race-attributes.csv",
    as.is = TRUE,
    header = TRUE 
    )

# assign the attributes to the network
gaNetU %v% "Age" <- attrs[,1]
gaNetU %v% "Race" <- attrs[,2]

```

Now that these are assigned as an attribute, we can reference them using the `%v%` operator. For example, let's look at the values for the `Race` attribute.

```{r}

# print out the values for each node
gaNetU %v% "Race"

# use the table() function to count each value
table( gaNetU %v% "Race" )

# let's recode the single 4 to a 1
race.recoded <- attrs[,2]
race.recoded[ race.recoded == 4 ] <- 1

# now assign the recoded value
gaNetU %v% "Race" <- race.recoded

```

Now, let's use the `Race` attribute and the `Age` attribute in a plot. We will color the nodes based on `Race` and size the nodes based on `Age`. Note that for `Age`, we are going to need to use the `rescale()` function.

```{r}

# create the colors for race
node.cols <- gaNetU %v% "Race"
node.cols[ gaNetU %v% "Race" == 1 ] <- "#eb105d"
node.cols[ gaNetU %v% "Race" == 2 ] <- "#5773fa"
node.cols[ gaNetU %v% "Race" == 3 ] <- "#37cf00"

# define the rescale function
rescale <- function( nchar, low, high ){
  min_d <- min( nchar )
  max_d <- max( nchar )
  rscl  <- ( ( high - low )*( nchar - min_d ) ) / ( max_d - min_d ) + low
  rscl
}

# now, plug our pieces into our plot
gplot( 
  gaNetU, 
  gmode = "graph",
  edge.col = "grey40", 
  vertex.col = node.cols,
  vertex.cex = rescale( gaNetU %v% "Age", 0.5, 2 ),
  coord = coords,
  main = "PINS Get\n Along With Network (Undirected)"
  )

# add a legend
legend( "topright", 
        legend=c( "White", "Black", "Hispanic" ), 
        col = unique( node.cols ), 
        pch = 19, 
        pt.cex=1
        )

```

*Think about the structure again. What do you notice about race or age?*  

*How might we go about incorporating this information into a model of the network?*  

<br>

# **Getting Started with the `ergm` Package and the `ergm()` Function**  

First things first, we need to install the `ergm` package and load the library of functions. 

```{r, eval=FALSE}

# clear the workspace
rm( list = ls() )

# install the ergm package
install.packages( "ergm" )

# load the ergm package
library( ergm )

# take a look at the functionality
help( package = "ergm" )

```

<br>

If you look at the `ergm()` function using `?ergm`, then you will see an extensive help file on the function.

<br>

## The `ergm()` Function

The `ergm()` function takes two arguments:  

* an object of class `network` (the dependent variable)  

* and some terms (i.e. network configurations)

Thus, the model form looks like this: `model <- ergm(network ~ term)`. Recall from the Introduction to ERGMs lecture that the general expression of the model is:  

$logit\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = \sum_{k=1}^\kappa \theta_k\delta_{z_k(y)}$  

As with logistic regression, the logit transformation can be used to re-express the equation as the conditional probability of a tie:

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(\theta_1\delta_{z_1(y)+\theta_2\delta_{z_2}(y)...})$   

Here, the coefficients are expressed as the conditional log-odds of a single actor pair. That is, how likely we are to see a tie between *i* and *j*, given some model terms. *So, what are those model terms or **network configurations**?*  

We can view all of the network statistics that have been programmed by using the `?ergm.terms` command. You can also use the `(vignette("ergm-term-crossRef"))` command to show you a bit more info about the model terms.  

<br>

## **Edge independence (Bernoulii/Simple Random graphs)**  

The ERGM expresses the probability of observing a tie between nodes *i* and *j* given some terms (i.e. network configurations). The edge independence model of Erdos and Renyi (1959) uses a single term, the number of edges in the graph, to represent the probability of a tie:   

$P(Y=y)=\Bigg(\frac{1}{c}\Bigg) exp \big\{\theta L(y) \big\}$  

In the `ergm()` function, this term is `edges`. You can see the help on the edges term using `?"edges-ergmTerm"`. Note the difference, we are calling `edges` within the `ergmTerm` help page. Let's take a look at this model:

```{r, message=FALSE}

# run the model
edge.indep.gaNetU <- ergm( gaNetU ~ edges ) 

# check out the summary
summary( edge.indep.gaNetU )

# note that the ergm() function creates an object of class ergm
class( edge.indep.gaNetU )
names( edge.indep.gaNetU )

```

First, the summary shows the coefficient $\theta$ from the equation above. The value of `r round( edge.indep.gaNetU$coefficients[1], 2 )` indicates that the density of the network is below .5 or 50%. An `edges` term of 0 would represent 50% or 0.5 density. As we saw above, the density of the `gaNetU` network is `r round( den, 3 )`.   

In the general formulation of the ERGM, the $\delta$ represents the *change statistic*, or the change in the statistic of interest when an edge is added (i.e. $Y_{ij}$) goes from 0 to 1). The change statistic for the `edges` term is always 1, so we can think of the probability of a tie between *i* and *j* as the logit of the coefficients for the `edges` term. Specifically, we can use the calculation that is usual for a logistic regression to interpret the coefficient:  


$\frac{1}{1 + e^{-(\theta_1X_1)}}$

<br>

If we plug in the value of `r round( edge.indep.gaNetU$coefficients[1], 2 )` that is returned by the `ergm()` function, we get:  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(\theta_{edges} \times \delta_{edges})$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-5.39 \times 1)$    

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = \frac{1}{1 + e^{-(-5.39 \times 1)}} = 0.005$    

<br>

*Does the value `r round(plogis(-5.39),3 )` look familiar?*  

The value of `r round( plogis( -5.39 ), 3 )` is returned by using the `plogis()` function. Use the `?plogis` command to examine the help file for this function.

<br>

```{r}

# we could write it out 
plogis( -5.39 * 1 )

# or, we could pull from the model object
plogis( edge.indep.gaNetU$coefficients[1] * 1 )

```

*So what is this?* Recall that the ERGM expresses the probability of observing a tie between nodes *i* and *j* given some terms (i.e. network configurations). The edge independence model of Erdos and Renyi (1959) uses a single term, the number of edges in the graph, to represent the probability of a tie. So, here we are saying that the probability of a tie between two nodes is `r plogis( edge.indep.gaNetU$coefficients[1] * 1 )`. 

*Does that help us understand the structure in the network?* 

Sort of, but it tells us about as much as the random network we plotted above. We can extend this model to include characteristics of nodes.

<br>

## **Adding Nodal Covariates**  

So far, we have assumed that the probability of a tie is independent of any nodal attribute. We could relax this assumption and test two hypotheses:  

* Nodes differ in their degree based on their race.  

* Nodes that are the same race are more likely to share ties (i.e. *homophily*).

<br>

We can test these hypotheses using the `nodefactor` (for categorical attributes [for continuous attributes use `nodecov`]) and `nodematch` (for categorical attributes [for continuous attributes use `absdiff`]) terms. Take a look at the description of the term `nodefactor` term using `?nodefactor`.

<br>

### **Testing the Degree Effects of Race/Ethnicity**

Why make these hypotheses? First, let's take a look at the degree distribution for race. Let's compare the mean degree for each group:

```{r}

# mean degree for white
round( mean( degree( gaNetU, gmode = "graph", cmode = "degree" )[gaNetU %v% "Race" == 1] ), 2 )

# mean degree for black
round( mean( degree( gaNetU, gmode = "graph", cmode = "degree" )[gaNetU %v% "Race" == 2] ), 2 )

# mean degree for hispanic
round( mean( degree( gaNetU, gmode = "graph", cmode = "degree" )[gaNetU %v% "Race" == 3] ), 2 )

```

*Now, how are the mean degrees different for each racial group?* 

*Are these differences due to random variation?*

```{r}

# let's add the nodefactor term for race to our model
race.gaNetU <- ergm( 
  gaNetU ~ edges 
  + nodefactor( "Race" )
  ) 

summary( race.gaNetU )

```

Note that the term adds one network statistic to the model for each categorical value of the variable we have passed. The first category is excluded as the reference category. The first category is white (which is coded as 1), so it is automatically excluded and serves as the referent category. This can be overriden if we want to.

For the `nodefactor` term, positive values indicate that a node with that particular value of the attribute is *more likely* to have an edge, relative to the referent category. Alternatively, a negative value indicates that a node with that particular value of the attribute is *less likely* to have an edge, relative to the referent category. 

*What does the model tell us?*

<br>

Let's look at this for our example. Looking at the table we see:  

* the term `r names( race.gaNetU$coefficients )[2]` has a value of `r round( race.gaNetU$coefficients[2], 2 )`, but is not significantly different from zero at the *p<0.5* level. Thus, the difference in degree for white and black that we observed above is consistent with random variation.  

* the term `r names( race.gaNetU$coefficients )[3]` has a value of `r round( race.gaNetU$coefficients[3], 2 )` and is  significantly different from zero at the *p<0.5* level. Thus, compared to whites, the probability of a tie between *i* and *j* is lower if either *i* or *j* are Hispanic.  

Recall that in the general formulation of the ERGM, the $\delta$ represents the *change statistic*, or the change in the statistic of interest when an edge is added (i.e. $Y_{ij}$) goes from 0 to 1). The change statistic for the `nodefactor` term is different from the `edges` term we saw above. If the predictor is categorical, the value of the change statistic is 0, 1 or 2. Specifically:  

* If neither of the nodes have the characteristic of interest, the change statistic is 0.  

* A value of 2 indicates that *both* of the nodes in the dyad have the characteristic.

<br>

Again, let's use the calculation that is usual for a logistic regression to interpret the coefficient:  


$\frac{1}{1 + e^{-(\theta_1X_1)}}$

<br>

Using the coefficient of `r round( race.gaNetU$coefficients[3], 2 )`, the predicted probability of a tie between *i* and *j* if they are **both** Hispanic is:

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(\theta_{edges} \times \delta_{edges} + \theta_{race} \times \delta_{race})$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic((-4.91 \times 1) + (-1.14 \times 2))$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-4.91 + -2.28)$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-7.19) = 0.0008$  

<br>

  The value of `r round( plogis( -7.19 ), 5 )` is returned by using the command `plogis()`. We can see this by adding the equation elements to the `plogis()` function.

```{r}

plogis(
    race.gaNetU$coefficients[1]*1  # the edges term
  + race.gaNetU$coefficients[3]*2  # the nodefactor hispanic term
  )

# rounded
round( plogis( race.gaNetU$coefficients[1]*1 + race.gaNetU$coefficients[3]*2 ), 5 )

```

What is the predicted probability of a tie between *i* and *j* if only **one** is Hispanic?:

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(\theta_{edges} \times \delta_{edges} + \theta_{race} \times \delta_{race})$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic((-4.91 \times 1) + (-1.14 \times 1))$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-4.91 + -1.14)$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-6.05) = 0.002$  

The value of `r round( plogis( -6.05 ), 3 )` is returned by using the command `plogis()`. We can see this by adding the equation elements to the `plogis()` function.

```{r}

plogis(
    race.gaNetU$coefficients[1]*1
  + race.gaNetU$coefficients[3]*1  # NOTE: we are only multiplying by 1!!!
  )

# rounded
round( plogis( race.gaNetU$coefficients[1]*1 + race.gaNetU$coefficients[3]*1 ), 3 )

```

Note that this is quite a change from having **two** nodes who are *Hispanic*. This difference in the probability of a tie shows you that *Hispanics* are less connected to the network, relative to other race/ethnicities.  

*Finally, what is the predicted probability of a tie between i and j if only both are White?*

<br>

### **Testing Homophily on Race/Ethnicity**

Now let's look at a different hypothesis: Nodes of the same race/ethnicity are more likely to share ties (i.e. *homophily*). We can test this using the `nodematch` term. But first, let's look at the *mixing* between each category value with the `mixingmatrix()` function. This function returns homophilous ties in the diagonal and heterophilous ties in the off-diagonal. To see more on the `mixingmatrix()` function, see the help, `?mixingmatrix`.

```{r}

mixingmatrix( gaNetU, "Race" )

```

*Looking at the mixing matrix for **race**, what patterns do you see?*  

Before we estimate the model for homophily, let's take a look at the `nodematch` term to see its functionality. You can do so using `?"nodematch-ergmTerm"`. (note the use of help here is a bit different).

Now, let's estimate the model for homophily.

```{r}

homophily.gaNetU <- ergm( 
  gaNetU ~ edges 
  + nodematch( "Race" )  # add the term for homophily
  ) 

summary( homophily.gaNetU )


```

Note that the term adds one network statistic to the model for the variable. For the `nodematch` term, positive values indicate that for a pair of nodes with the **same** attribute value, an edge is *more likely*. Alternatively, a negative value indicates that for a pair of nodes with the **same** attribute value, an edge is *less likely*. Thus, positive coefficients indicate the presence of **homophily** and negative coefficients indicate the presence of **heterophily**.

Let's work through our example to see the interpretation of the coefficient. Looking at the table we see:  

* the term `r names( homophily.gaNetU$coefficients )[2]` has a value of `round( homophily.gaNetU$coefficients[2], 2 )`, indicating that ties are more likely among nodes with the same value for the variable **Race**.  

<br>

Recall that in the general formulation of the ERGM, the $\delta$ represents the *change statistic*, or the change in the statistic of interest when an edge is added (i.e. $Y_{ij}$) goes from 0 to 1). The change statistic for the `nodematch` term is similar to the `edges` term we saw above. If the predictor is categorical, the value of the change statistic is 0 or 1. Specifically:  

* If *i* and *j* have the same value for a categorical covariate the change statistic is 1.  

* If *i* and *j* **do not** have the same value for a categorical covariate the change statistic is 0.  

<br>

Again, let's use the calculation that is usual for a logistic regression to interpret the coefficient:  

$\frac{1}{1 + e^{-(\theta_1X_1)}}$

<br>

Using the coefficient of `round( homophily.gaNetU$coefficients[2], 2 )`, the predicted probability of an edge between nodes with the **same** race/ethnicity is:

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(\theta_{edges} \times \delta_{edges} + (\theta_{race.homophily} \times \delta_{race.homophily}))$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-6.62 \times 1 + 1.98 \times 1)$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-6.62 + 1.98)$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-4.64) = 0.0096$  

<br>

The value of `r round( plogis( -4.64 ), 4 )` is returned by using the command `plogis()`.  

```{r}

plogis( homophily.gaNetU$coefficients[1]*1 + homophily.gaNetU$coefficients[2]*1 )

```

Now, what if we where interested in homophily differences by race. That is, does homophily differ for the groups? This is referred to as *differential homophily* and can be tested using the `diff=TRUE` argument in the `nodematch` term in the `ergm()` function.

```{r}

d.homophily.gaNetU <- ergm( 
  gaNetU ~ edges 
  + nodematch( "Race", diff=TRUE ) # not the addition
  ) 

summary( d.homophily.gaNetU )

```

*What is the interpretation of the model?*

<br>

### **Accounting for Degree and Homophily**

In the model examining homophily, note that we excluded the `nodefactor` term. This inherently assumes that there are no degree differences between the nodes based on `Race`. As a result, we are not accounting for an important feature of the network. Specifically, we could observe homophily on `Race` simply because there are differences in the degree distribution by the values for the attribute `Race`. Let's take this into account by reestimating the model and including both the `nodefactor` and the `nodematch` terms.

```{r}

DH.gaNetU <- ergm( 
  gaNetU ~ edges
  + nodefactor( "Race" )            
  + nodematch( "Race", diff=FALSE )
  ) 

summary( DH.gaNetU )

```

**Yikes**! Look at those estimates. *What is the problem?*

<br>

## **Dyad Dependence: Modeling Endogenous Network Structures**  

All of the models above are **edge indepedent** or **dyad independent** models in that the probability of a tie from *i* to *j* is not dependent on a tie to *k*. But, in reality, many network structures are formed due to dependencies between dyads. For example, whether I decide to befriend you may depend on whether we have a shared friend in common. That is **dyad dependence**.

A major strength of the ERGM is the ability to model such endogenous network structures. In the models above, we observed homophily for the attribute `Race`. The model proposed that the probability of a tie was more likely to occur between *i* and *j* if they both are of the same race/ethnicity. This is because we observed many same-race/ethnicity dyads in the mixing matrix:

```{r, echo=FALSE, message=FALSE, warning=FALSE}

mixingmatrix( gaNetU, "Race" )

```

But, we may observe such mixing due to transitivity in a network. If we wanted to examine homophily, we would want to account for the tendency for transitive relationships to form. 

Let's estimate a model that includes the `gwesp` term. This terms add a count of the edgewise shared parterns in a network to the model. Positive values indicate that there is a tendency for an edge to form between *i* and *j* if they have a shared partner. Note that when we move to the dyad dependence model, the estimation gets a bit more complicated. We won't go into the details now, but you will see some differences in the code below.

```{r, message=FALSE, warning=FALSE}

triad.gaNetU <- ergm( 
  gaNetU ~ edges
  + nodematch( "Race", diff=TRUE )
  + gwesp( decay = 0.25, fixed = TRUE ), # here is our gwesp term
  
  control = control.ergm(
    seed = 605 ) # here we use the control argument to set the seed to reproduce results
  ) 

summary( triad.gaNetU )

```

*What is the interpretation of the model?*

<br>

# **Modeling Status in the PINS *Power/Influence* Network**  

Let's walk back through what we covered above with a directed network, noting differences in the model as we go.

For the *power and influence* network, individuals could have asymmetric nominations. That is, *i* could nominate *j* and *j* didn't necessarily nominate *i*. We will keep this asymmetry so that we can treat the network as directed.

```{r}

# clear the workspace since we will recycle object names
rm( list = ls() )

# set the location for the file
loc <- "https://github.com/jacobtnyoung/sna-textbook/raw/main/data/data-PINS-power-w1-adj.csv"

# read in the .csv file
piMat <- as.matrix(
  read.csv( 
    loc,
    as.is = TRUE,
    header = TRUE,
    row.names = 1 
    )
  )

piNetD <- as.network( piMat, directed = TRUE )

```

<br>


```{r, fig.show="hide"}

# Set the coordinates
set.seed( 605 )
coords <- gplot( piNetD )

```


```{r, echo=TRUE, fig.align="center"}

gplot( 
  piNetD, 
  gmode = "digraph",
  edge.col="grey40", 
  vertex.col="#5bf5b5",
  coord = coords,
  main = "PINS Power/Influence Network (Directed)"  
  )

```

*Think about the structure here. What do you notice?*  

*How might we go about incorporating this information into a model of the network?*  

<br>

Before we get going, let's define some graphical objects we will use.

```{r}

# define the number of nodes
g <- dim( piMat )[1]

# define the number of edges
l <- sum( piMat )/2

# define the density
den <- l / ( g *( g - 1 ) ) 

den

```

*What is the interpretation of the density?*  

<br>

Recall that the exponential random graph model seeks to model the underlying processes that generated the observed network. Let's create a random graph with the same nodes, edges, and density as the `piNetD` network and compare them by using the `rgraph()` function in the `sna` package:

```{r, message=FALSE}

# set the seed to reproduce these results
set.seed( 605 )

# generate the random graph
random.graph <- rgraph(
  g,                   # the number of nodes in the network
  1,                   # we want just 1 random graph 
  tprob = den,         # the density of the network 
  mode = "digraph"    # it is directed 
  )

# now coerce the random graph to a network object
random.net <- as.network( random.graph, directed = FALSE )

```

<br>

We can now compare our observed data with a graph that has the same density and the edges are randomly distributed over the nodes.

```{r}

# set the margins
par( mfrow=c( 1,2 ), 
     mar=c( 0.1, 0.5, 2, 0.5 ) )

# set the seed
set.seed( 605 )

# create the first plot
gplot( 
  piNetD, 
  gmode = "digraph",
  edge.col="grey40", 
  vertex.col="#5bf5b5",
  coord = coords,
  main = "PINS Power/Influence Network (Directed)"  
  )

# create the second plot
gplot( 
  random.net, 
  gmode = "digraph",
  edge.col = "grey40", 
  vertex.col="#069e6e",
  main = "Random network"
  )

```

*How is the Power/Influence network different from the random network?*  

<br>

### **Adding Attributes (revisited)**

We can use the same attributes as above. Some we cleared the workspace, we will want to reload and recreate the attributes.

```{r}

# define the attributes object
attrs <- read.csv( 
    "https://raw.githubusercontent.com/jacobtnyoung/sna-textbook/main/data/data-PINS-w1-age-race-attributes.csv",
    as.is = TRUE,
    header = TRUE 
    )

# let's recode the single 4 to a 1
race.recoded <- attrs[,2]
race.recoded[ race.recoded == 4 ] <- 1


# assign the attributes to the network
piNetD %v% "Age" <- attrs[,1]

# now assign the recoded value
piNetD %v% "Race" <- race.recoded

```

Now, let's use the `Race` attribute and the `Age` attribute in a plot. We will color the nodes based on `Race` and size the nodes based on `Age`. Note that for `Age`, we are going to need to use the `rescale()` function.

```{r}

# create the colors for race
node.cols <- piNetD %v% "Race"
node.cols[ piNetD %v% "Race" == 1 ] <- "#eb105d"
node.cols[ piNetD %v% "Race" == 2 ] <- "#5773fa"
node.cols[ piNetD %v% "Race" == 3 ] <- "#37cf00"

# define the rescale function
rescale <- function( nchar, low, high ){
  min_d <- min( nchar )
  max_d <- max( nchar )
  rscl  <- ( ( high - low )*( nchar - min_d ) ) / ( max_d - min_d ) + low
  rscl
}

# now, plug our pieces into our plot
gplot( 
  piNetD, 
  gmode = "digraph",
  edge.col="grey40", 
  vertex.col=node.cols,
  vertex.cex = rescale( piNetD %v% "Age", 0.5, 2 ),
  coord = coords,
  main = "PINS Power/Influence Network (Directed)"  
  )

# add a legend
legend( "topright", 
        legend=c( "White", "Black", "Hispanic" ), 
        col = unique( node.cols ), 
        pch = 19, 
        pt.cex=1
        )

```

*Think about the structure again. What do you notice about race or age?*  

*How might we go about incorporating this information into a model of the network?*  

<br>

## **Adding Nodal Covariates**  

Let's test three new hypotheses:  

* Nodes differ in their degree based on their age.  

* Nodes that are of similar age are more likely to share ties (i.e. *homophily*).

* Nodes reciprocate ties.

<br>

We can test these hypotheses using the `nodecov` (since age is continuous) and `absdiff` terms. And, for reciprocity, a new term `mutual`. 

<br>

### **Testing the Degree Effect of Age**

```{r}

# let's add the nodecov term for age to our model
age.d.piNetD <- ergm( 
  piNetD ~ edges 
  + nodecov( "Age" )
  ) 

summary( age.d.piNetD )

```

For the `nodecov` term adds one network statistic to the model that sums the attribute of interest for the two nodes comprising the end points of each edge in the network. Positive values indicate that as the continuous attribute increases, the edge is *more likely*, relative to lower values. Note the difference here compared to the interpretation for categorical attributes. 

*What does the model tell us?*

<br>

Let's look at this for our example. Looking at the table we see:  

* the term `r names( age.d.piNetD$coefficients )[2]` has a value of `r round( age.d.piNetD$coefficients[2], 2 )`, and is significantly different from zero at the *p<0.5* level. 

Recall that in the general formulation of the ERGM, the $\delta$ represents the *change statistic*, or the change in the statistic of interest when an edge is added (i.e. $Y_{ij}$) goes from 0 to 1). The change statistic for the `nodecov` term is different from the `edges` term we saw above. If the predictor is continuous, we interpret one-unit changes in the attribute.

<br>

Using the coefficient of `r round( age.d.piNetD$coefficients[2], 2 )`, if we increase `Age` by 1 unit, the predicted probability of a tie between *i* and *j* is:

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(\theta_{edges} \times \delta_{edges} + \theta_{age} \times \delta_{age})$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic((-8.87 \times 1) + (0.02 \times 1))$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-8.87 + 0.02)$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-8.85) = 0.0001$  

<br>

The value of `r round( plogis( -8.85 ), 5 )` is returned by using the command `plogis()`. We can see this by adding the equation elements to the `plogis()` function.

```{r}

plogis( 
  age.d.piNetD$coefficients[1]*1  # the edges term
  + age.d.piNetD$coefficients[2]*1  # the nodecov term for age
  )

```

<br>

The term for `Age` above tells us that degree is correlated with age. But, remember that this network is directed. So, we could test two additional hypotheses:

  + Indegree increases with age
  + Outdegree decreases with age

Note that we use the `nodecov` term for continuous attributes. But, we can refine this for directed graphs using the `nodeicov` and `nodeocov` terms. (For categorical attributes, we use `nodeifactor` and `nodeofactor`). 

For the `nodeicov` term, positive values indicate that as the continuous attribute increases, then *i* is more likely to *receive* and tie from *j* (because it is the indegree). For the `nodeocov` term, positive values indicate that as the continuous attribute increases, then *i* is more likely to *send* and tie to *j* (because it is outdegree).     

Let's check it out in the model.

```{r}

# let's add the nodeicov and nodeocov terms for age to our model
age.sr.piNetD <- ergm( 
  piNetD ~ edges 
  + nodeicov( "Age" ) # effect for receiving ties
  + nodeocov( "Age" ) # effect for sending ties
  ) 

summary( age.sr.piNetD )

```

To remind you, in this model we have separated the effect of `Age` on sending ties and receiving ties. *What is the interpretation of the model estimates?*

<br>

### **Testing Homophily on Age**

Now let's look at a different hypothesis: Nodes of similar age are more likely to share ties (i.e. *homophily*). We can test this using the `absdiff` term. Before we estimate the model for homophily, let's take a look at the `absdiff` term to see its functionality. You can do so using `?"absdiff-ergmTerm"`. (note the use of help here is a bit different).

Now, let's estimate the model for homophily.

```{r}

age.h.piNetD <- ergm( 
  piNetD ~ edges 
  + nodeicov( "Age" ) 
  + nodeocov( "Age" ) 
  + absdiff( "Age" ) # homophily for age  
  ) 

summary( age.h.piNetD )

```

Note that the term adds one network statistic to the model for the variable that takes the absolute difference in the value of the attribute for each node. This means that negative values will indicate homophily. For the `absdiff` term, negative values indicate that for a pair of nodes with **similar** attribute values, an edge is *more likely*. Put differently, as the absolute value of the difference between each node on the attribute gets larger, the probability of a tie declines. Thus, negative coefficients indicate the presence of **homophily** and positive coefficients indicate the presence of **heterophily**.

<br>

Using the coefficient of `r round( age.h.piNetD$coefficients[4], 2 )`, the predicted probability of an edge between nodes with the **same** age is:

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(\theta_{edges} \times \delta_{edges} + (\theta_{age.homophily} \times \delta_{age.homophily}))$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-8.67 \times 1 + -0.03 \times 0)$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-8.67 + 0)$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-8.67) = 0.00017$  

<br>

The value of `r round( plogis( -8.67 ), 5 )` is returned by using the command `plogis()`.  

```{r}

plogis( age.h.piNetD$coefficients[1]*1 + age.h.piNetD$coefficients[4]*0 )

```

<br>

## **Testing for Reciprocity**  

Now, let's test whether the probability of a tie for *i* to *j* depends on the presence of a tie from *j* to *i* (i.e. reciprocity).

```{r, message=FALSE, warning=FALSE}

recp.piNetD <- ergm( 
  piNetD ~ edges
  + nodeicov( "Age" ) 
  + nodeocov( "Age" ) 
  + absdiff( "Age" )
  + mutual,          # add the term for reciprocity
  
  control = control.ergm(
    seed = 605 ) # here we use the control argument to set the seed to reproduce results
  ) 

summary( recp.piNetD )

```

*What is the interpretation of the coefficient?*

<br>

Using the coefficient of `r round( recp.piNetD$coefficients[5], 2 )`, the predicted probability of an edge between *i* and *j* if a tie exist between *j* and *i* is:

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(\theta_{edges} \times \delta_{edges} + (\theta_{reciprocity} \times \delta_{reciprocity}))$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-8.57 \times 1 + 1.74 \times 1)$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-8.57 + 1.74)$  

$\Bigg(P \Bigg(Y_{ij}=1 \> | \> n \> actors, Y_{ij}^C\Bigg) \Bigg) = logistic(-6.83) = 0.0011$  

<br>

The value of `r round( plogis( -6.83 ), 4 )` is returned by using the command `plogis()`.  

```{r}

plogis( recp.piNetD$coefficients[1]*1 + recp.piNetD$coefficients[5]*1 )

```

<br>

----

# **Wrapping up...**

In this lab, you were introduced to exponential family of random graphs in R using the `ergm` package. We worked through different dependence specifications of the model reviewed in the [Introduction to Exponential Random Graph Models (ERGMs) lecture](../lectures/lecture-08-ergm.pdf). We also showed how to incorporate node level attributes and endogenous network structures.

<br>

### ***Questions?***

<br>

##### ***Please*** report any needed corrections to the [Issues](https://github.com/jacobtnyoung/SAND/issues/new) page. Thanks!